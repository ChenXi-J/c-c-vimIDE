// This project is powered by tencent ncnn.

// Author: Peng Jin
// Contact: 871461071 at qq.com
// Organization: www.oetlink.com


// Version: omit...

// Version: 0.21
// Date: 2018/12/11
// Description: change from ncnn to Tengine and add head-track-dot

// Version: omit...

// Version: 0.5
// Date: 2019/3/27
// Description: change from Tengine count_version 0.43 to ncnn, two thread, image detect

// Version: 0.51
// Date: 2019/3/29
// Description: video detect

// Version: 0.52
// Date: 2019/3/29
// Description: passenger count

// Version: 0.53
// Date: 2019/4/3
// Description: add time test

// Version: 0.54
// Date: 2019/4/10
// Description: add ncnn::allocator and ncnn::option

// Version: 0.55
// Date: 2019/4/13
// Description: add int8/float32 switch: net.use_int8_inference

// Version: 0.56
// Date: 2019/4/17
// Description: int8 offline model, net reuse

// Version: 0.58
// Date: 2019/4/26
// Description: set usb-camera input to 320*240, support video save, add if_show_video control

// Version: 0.60
// Date: 2019/4/29
// Description: add in and out people of two thread together: in_people/out_people, list param of counter, thread_id from 1/2 to 0/1


#include <stdio.h>
#include <vector>
#include <unistd.h>
#include <iostream>
#include <sstream>
#include <fstream>
#include <iomanip>
#include <string>
#include <sys/time.h>
#include <time.h>
#include <thread>
#include <memory>
#include <mutex>
#include <atomic>
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/imgproc/imgproc.hpp>


#include "platform.h"
#include "net.h"
#include "cpu.h"

#include "count.h"

#include <pthread.h>
#include <sys/shm.h>
#include <condition_variable>
#include "oepc_main.h"
#include "../include/sem.h"

std::mutex mtx_show;
ncnn::Net net;

struct{
	pthread_mutex_t mutex;
	pthread_cond_t cond;
	int data;
}image_cond[2];

static cv::Mat g_image[2];

int in_people[2] = { 0 };
int out_people[2] = { 0 };
std::mutex mtx_in_out;

//static int sem_reco[2];

static int get_thread(int thread_id, RecognitionStu *recognition_shm,  std::string window_name)
{
	int total_frame = 0;
	int frame_cout = 100;			//100 is about 5 seconds, time to cout a piece of information
	struct timeval t2, t3;
	float trans_total_time =0;			//calculate time
	float trans_run_time;
	float avg_time;
	float trans_min_time=1000;
	float trans_max_time =-1;
	cv::Mat image;

	RecognitionStu recognition;
	int cpus =0;
	cpu_set_t mask;
    cpu_set_t get;

    cpus = sysconf(_SC_NPROCESSORS_CONF);
    printf("this system has %d processor(s)\n", cpus);
    
    CPU_ZERO(&mask);
    CPU_SET(0, &mask);
    CPU_SET(1, &mask);

    /* 设置cpu 亲和性(affinity)*/
    if (pthread_setaffinity_np(pthread_self(), sizeof(mask), &mask) < 0) {
        fprintf(stderr, "set thread affinity failed\n");
    }   
    
    /* 查看cpu 亲和性(affinity)*/
    CPU_ZERO(&get);
    if (pthread_getaffinity_np(pthread_self(), sizeof(get), &get) < 0) {
        fprintf(stderr, "get thread affinity failed\n");
    }   

    /* 查看当前线程所运行的所有cpu*/
    for (int i = 0; i < cpus; i++) {
        if (CPU_ISSET(i, &get)) {
            printf("this thread %d is running in processor %d\n", (int)pthread_self(), i); 
        }   
    }


	//cv::VideoWriter writer(VIDEO_PATH+window_name+".avi", CV_FOURCC('M', 'J', 'P', 'G'), 60.0, cv::Size(IMAGE_WIDTH, IMAGE_HEIGHT));
	std::cout << VIDEO_PATH+window_name+".avi\n";

	while(1)
	{
		//if(!recognition_shm->run)
		//{
		//	sem_p(sem_reco[thread_id]);
		//}

		gettimeofday(&t2, NULL);

		while(recognition_shm->imagelen == 0)usleep(1000);
		//if(recognition_shm->imagelen == 0)
		//{
		//	//std::cout << "buf empty\n";
		//	usleep(1000);
		//	continue;
		//}
		total_frame++;

		{ //trans
			pthread_mutex_lock(&recognition_shm->shareMtx);

			memcpy(recognition.imagebuf, recognition_shm->imagebuf, recognition_shm->imagelen);
			recognition.imagelen = recognition_shm->imagelen;

			recognition_shm->imagelen = 0; //加载下一幅图片

			pthread_mutex_unlock(&recognition_shm->shareMtx);

			cv::_InputArray pic_arr_1(recognition.imagebuf, recognition.imagelen);
			//image = cv::imdecode(pic_arr_1, CV_LOAD_IMAGE_COLOR);

			image = cv::imdecode(pic_arr_1, cv::IMREAD_COLOR);

			pthread_mutex_lock(&image_cond[thread_id].mutex);
			g_image[thread_id] = image;
			pthread_mutex_unlock(&image_cond[thread_id].mutex);

			//pthread_cond_signal(&image_cond[thread_id].cond);


		}
			//writer << image;

			gettimeofday(&t3, NULL);
		trans_run_time = (float)((t3.tv_sec * 1000000 + t3.tv_usec) - (t2.tv_sec * 1000000 + t2.tv_usec)) / 1000;
		if (trans_run_time > trans_max_time){ trans_max_time = trans_run_time; }
		if (trans_run_time < trans_min_time){ trans_min_time = trans_run_time; }
		trans_total_time += trans_run_time;
		//time-end--------------------------------------------------------------

		if (0 == total_frame % frame_cout)
		{
			avg_time = trans_total_time / frame_cout;
			std::cout << window_name << " " << total_frame - frame_cout << "~" << total_frame << " frame,";
			std::cout << "  trans avg: " << avg_time << "ms, " << "max: " << trans_max_time << "ms, " << "min: " << trans_min_time << "ms\n";
			trans_total_time = 0;
			trans_max_time = -1;
			trans_min_time = 1000;
		}
	}
}

static int run_thread(int thread_id, RecognitionStu *recognition_shm, bool if_save_video, bool if_show_image, std::string thread_name)
{
	Count counter;
	counter.detect_thre = 0;		//detect threshold
	counter.distance_thre = 80;	//to judge if two heads belong to one track
	counter.lost_frame_thre = 10;	//to judge if a track need to be delete
	counter.y_thre_in = 100;		//track distance of in people
	counter.y_thre_out = -100;		//track distance of out people

	int in_all_thread = 0;
	int out_all_thread = 0;

	cv::Mat image;

	//cap >> image;

	std::vector<Object> objects;
	ncnn::Mat in;
	ncnn::Mat out;
	const int target_size_w = IMAGE_WIDTH;//320;  // same as img_w
	const int target_size_h = IMAGE_HEIGHT;//240;   // same as img_h
	int img_w = IMAGE_WIDTH;//image.cols;
	int img_h = IMAGE_HEIGHT;//image.rows;
	const float mean_vals[3] = { 127.5f, 127.5f, 127.5f };
	const float norm_vals[3] = { 0.007843, 0.007843, 0.007843 };
	static const char* class_names[] = { "background", "head", "head2", "head3", "head4" };


	int total_frame = 0;
	int frame_cout = 100;			//100 is about 3 seconds, time to cout a piece of information
	int frame_time = 5;			//5 is about 0.2 seconds, time to show this_run_time
	struct timeval t0, t1;
	float total_time;			//calculate time
	float this_run_time;
	int this_run_time_int;
	float avg_time;
	float min_time = 1000;
	float max_time = -1;
	std::ostringstream buffer;	//show time
	std::string show_time;		//show time + ms


	int num_threads;
	int powersave;    //0:all cores, 1:small cores, 2:big cores

	if (0 == thread_id)
	{
		num_threads = 1;
		powersave = 2;
		std::cout << thread_name << "  set cpu done!" << "\n";
	}
	if (1 == thread_id)
	{
		num_threads = 1;
		powersave = 2;
		std::cout << thread_name << "  set cpu done!" << "\n";
	}
	else
	{
		num_threads = 1;
		powersave = 2;
		std::cout << thread_name << "  set cpu done!" << "\n";
	}


	ncnn::Option opt;
	opt.lightmode = true;
	opt.num_threads = num_threads;

	ncnn::set_default_option(opt);
	ncnn::set_cpu_powersave(powersave);
	ncnn::set_omp_dynamic(0);
	ncnn::set_omp_num_threads(num_threads);

	int cpus =0;
	cpu_set_t mask;
    cpu_set_t get;

    cpus = sysconf(_SC_NPROCESSORS_CONF);
    printf("this system has %d processor(s)\n", cpus);
    CPU_ZERO(&mask);
    CPU_SET(4, &mask);
    CPU_SET(5, &mask);

    /* 设置cpu 亲和性(affinity)*/
    if (pthread_setaffinity_np(pthread_self(), sizeof(mask), &mask) < 0) {
        fprintf(stderr, "set thread affinity failed\n");
    }   
    
    /* 查看cpu 亲和性(affinity)*/
    CPU_ZERO(&get);
    if (pthread_getaffinity_np(pthread_self(), sizeof(get), &get) < 0) {
        fprintf(stderr, "get thread affinity failed\n");
    }   

    /* 查看当前线程所运行的所有cpu*/
    for (int i = 0; i < cpus; i++) {
        if (CPU_ISSET(i, &get)) {
            printf("this thread %d is running in processor %d\n", (int)pthread_self(), i); 
        }   
    }

	time_t t;
	struct tm * lt;
	std::ostringstream date_time;
	std::string save_name;
	int frame_people_gone = 20;				//after 20 frames not detected people, stop record video
	bool video_recording = false;			//if video is recording
	//cv::Size sWH = cv::Size((int)cap.get(CV_CAP_PROP_FRAME_WIDTH), (int)cap.get(CV_CAP_PROP_FRAME_HEIGHT));
	cv::VideoWriter outputVideo;

	{
		int cpus;
		cpu_set_t mask;
		cpu_set_t get;

    	cpus = sysconf(_SC_NPROCESSORS_CONF);
    	printf("this system has %d processor(s)\n", cpus);
    	
    	//CPU_ZERO(&mask);
    	//CPU_SET(thread_id+4, &mask);

    	///* 设置cpu 亲和性(affinity)*/
    	//if (pthread_setaffinity_np(pthread_self(), sizeof(mask), &mask) < 0) {
    	//    fprintf(stderr, "set thread affinity failed\n");
    	//}   
    	
    	/* 查看cpu 亲和性(affinity)*/
    	CPU_ZERO(&get);
    	if (pthread_getaffinity_np(pthread_self(), sizeof(get), &get) < 0) {
    	    fprintf(stderr, "get thread affinity failed\n");
    	}   

    	/* 查看当前线程所运行的所有cpu*/
    	for (int i = 0; i < cpus; i++) {
    	    if (CPU_ISSET(i, &get)) {
    	        printf("this thread %d is running in processor %d\n", (int)pthread_self(), i); 
    	    }   
    	}
	}

	std::cout << thread_name << "    num_threads = " << num_threads << "      powersave = " << ncnn::get_cpu_powersave() << "\n";

	while (1)
	{

		//time-begin------------------------------------------------------------
		gettimeofday(&t0, NULL);
		//time-begin------------------------------------------------------------


		//获取图片
		{
			pthread_mutex_lock(&image_cond[thread_id].mutex);
			//pthread_cond_wait(&image_cond[thread_id].cond, &image_cond[thread_id].mutex);
			image = g_image[thread_id];
			pthread_mutex_unlock(&image_cond[thread_id].mutex);

		}


		/////////////////////////////////1. get_frame////////////////////////////////////////


		//cap >> image;
		if (image.empty())
		{
			//std::cout << "video end\n";
			continue;
		}
		total_frame++;

		/////////////////////////////////1. get_frame////////////////////////////////////////






		/////////////////////////////////2. extract_objects////////////////////////////////////////

		ncnn::Extractor ex = net.create_extractor();
		in = ncnn::Mat::from_pixels_resize(image.data, ncnn::Mat::PIXEL_BGR, img_w, img_h, target_size_w, target_size_h);
		in.substract_mean_normalize(mean_vals, norm_vals);
		ex.input("data", in);
		ex.extract("detection_out", out);


		objects.clear();
		for (int i = 0; i<out.h; i++)
		{
			const float* values = out.row(i);

			Object object;
			object.label = values[0];
			object.prob = values[1];
			object.left_top_x = values[2] * img_w;
			object.left_top_y = values[3] * img_h;
			object.right_bottom_x = values[4] * img_w;
			object.right_bottom_y = values[5] * img_h;
			object.width = object.right_bottom_x - object.left_top_x;
			object.height = object.right_bottom_y - object.left_top_y;
			object.center_x = (object.right_bottom_x + object.left_top_x) / 2.0;
			object.center_y = (object.right_bottom_y + object.left_top_y) / 2.0;
			if (object.width > object.width)
				object.radius = object.width / 2.0;
			else
				object.radius = object.height / 2.0;

			objects.push_back(object);
		}

		/////////////////////////////////2. extract_objects////////////////////////////////////////






		/////////////////////////////////3. post_process///////////////////////////////////////////

		counter.passenger_count(objects);		//match and track

		mtx_in_out.lock();
		in_people[thread_id] = counter.in_total;
		out_people[thread_id] = counter.out_total;
		in_all_thread = in_people[0] + in_people[1];
		out_all_thread = out_people[0] + out_people[1];
		mtx_in_out.unlock();

		if (counter.people_change)
		{
			pthread_mutex_lock(&recognition_shm->shareMtx);
			recognition_shm->people_change = true;
			recognition_shm->in_total = counter.in_total;
			recognition_shm->out_total = counter.out_total;
			pthread_mutex_unlock(&recognition_shm->shareMtx);

			std::cout << thread_name << "   in: " << counter.in_total << "   out: " << counter.out_total << "\n";

		}

		if (if_show_image || if_save_video)
		{
			//3.1. box and class

			for (size_t i = 0; i < objects.size(); i++)
			{
				const Object& obj = objects[i];

				//fprintf(stderr, "%d = %.5f at %.2f %.2f %.2f x %.2f\n", obj.label, obj.prob, obj.rect.x, obj.rect.y, obj.rect.width, obj.rect.height);

				cv::rectangle(image, cv::Rect(obj.left_top_x, obj.left_top_y, obj.width, obj.height), cv::Scalar(255, 255, 0), 2);

				char text[256];
				sprintf(text, "%s %.1f%%", class_names[obj.label], obj.prob * 100);

				int baseLine = 0;
				cv::Size label_size = cv::getTextSize(text, cv::FONT_HERSHEY_SIMPLEX, 0.5, 1, &baseLine);

				int x = obj.left_top_x;
				int y = obj.left_top_y - label_size.height - baseLine;
				if (y < 0) y = 0;
				if (x + label_size.width > img_w) x = img_w - label_size.width;

				cv::rectangle(image, cv::Rect(cv::Point(x, y), cv::Size(label_size.width, label_size.height + baseLine)), cv::Scalar(255, 255, 255), -1);

				cv::putText(image, text, cv::Point(x, y + label_size.height), cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));
			}

			//3.2. tracks

			for (auto each_track : counter.tracks)
			{
				Object pre_head = each_track.heads_in_this_track.front();

				for (auto each_head : each_track.heads_in_this_track)
				{
					if (2 == each_track.track_type)			//valid tracks
					{
						cv::line(image, cv::Point(each_head.center_x, each_head.center_y), cv::Point(pre_head.center_x, pre_head.center_y), cv::Scalar(0, 255, 255), 10);
						cv::circle(image, cv::Point(each_head.center_x, each_head.center_y), 10, cv::Scalar(0, 255, 255), -1);
					}
					else if (3 == each_track.track_type)	//invalid tracks
					{
						cv::line(image, cv::Point(each_head.center_x, each_head.center_y), cv::Point(pre_head.center_x, pre_head.center_y), cv::Scalar(100, 0, 0), 10);
						cv::circle(image, cv::Point(each_head.center_x, each_head.center_y), 10, cv::Scalar(100, 0, 0), -1);
					}
					else if (1 == each_track.track_type)	//matching tracks
					{
						cv::line(image, cv::Point(each_head.center_x, each_head.center_y), cv::Point(pre_head.center_x, pre_head.center_y), cv::Scalar(0, 0, 255), 2);
						cv::circle(image, cv::Point(each_head.center_x, each_head.center_y), 5, cv::Scalar(0, 255, 0), -1);
					}

					pre_head = each_head;
				}
			}

			//3.3. in and out people

			std::string in = "I:" + std::to_string(counter.in_total) + "/" + std::to_string(in_all_thread);

			std::string out = "O:" + std::to_string(counter.out_total) + "/" + std::to_string(out_all_thread);
			cv::rectangle(image, cv::Rect(cv::Point(2, img_h - 65), cv::Size(120, 63)), cv::Scalar(0, 0, 0), -1);
			cv::putText(image, in, cv::Point(7, img_h - 40), cv::FONT_HERSHEY_SIMPLEX, 0.8, cv::Scalar(255, 255, 255), 2);
			cv::putText(image, out, cv::Point(7, img_h - 10), cv::FONT_HERSHEY_SIMPLEX, 0.8, cv::Scalar(255, 255, 255), 2);



			//3.4. time

			if (0 == total_frame % frame_time) 
			{
				buffer.str("");
				this_run_time_int = this_run_time;
				buffer << this_run_time_int;
				show_time = buffer.str() + "ms";
				cv::rectangle(image, cv::Rect(cv::Point(img_w - 82, img_h - 35), cv::Size(80, 33)), cv::Scalar(0, 0, 0), -1);
				cv::putText(image, show_time, cv::Point(img_w - 77, img_h - 10), cv::FONT_HERSHEY_SIMPLEX, 0.8, cv::Scalar(255, 255, 255), 2);
			}
			else
			{
				cv::rectangle(image, cv::Rect(cv::Point(img_w - 82, img_h - 35), cv::Size(80, 33)), cv::Scalar(0, 0, 0), -1);
				cv::putText(image, show_time, cv::Point(img_w - 77, img_h - 10), cv::FONT_HERSHEY_SIMPLEX, 0.8, cv::Scalar(255, 255, 255), 2);
			}


		}


		if (if_show_image)
		{
			mtx_show.lock();
			cv::imshow(thread_name, image);
			cv::waitKey(1);
			mtx_show.unlock();
		}


		if (if_save_video)
		{
			if (counter.people_detected && !video_recording)
			{
				// start to record and open file
				time(&t); lt = localtime(&t);
				date_time.str("");
				date_time << "_" << lt->tm_year + 1900 << "_" << lt->tm_mon << "_" << lt->tm_mday << "_" << lt->tm_hour << "_" << lt->tm_min << "_" << lt->tm_sec;
				save_name = "../videos/output/" + thread_name + date_time.str() + ".avi";   //a-path
				//outputVideo.open(save_name, CV_FOURCC('M', 'P', '4', '2'), 5.0, sWH);
				video_recording = true;
			}
			if ((frame_people_gone == counter.frames_to_people_gone) && video_recording)
			{
				// stop record and close file
				outputVideo.release();
				video_recording = false;
			}
			if (video_recording)
			{
				// recording
				outputVideo << image;
			}
		}


		/////////////////////////////////3. post_process///////////////////////////////////////////





		//time-end--------------------------------------------------------------
		gettimeofday(&t1, NULL);
		this_run_time = (float)((t1.tv_sec * 1000000 + t1.tv_usec) - (t0.tv_sec * 1000000 + t0.tv_usec)) / 1000;
		if (this_run_time > max_time){ max_time = this_run_time; }
		if (this_run_time < min_time){ min_time = this_run_time; }
		total_time += this_run_time;
		//time-end--------------------------------------------------------------

		if (0 == total_frame % frame_cout)   //cout
		{
			avg_time = total_time / frame_cout;
			std::cout << thread_name << " " << total_frame - frame_cout << "~" << total_frame << " frame,";
			std::cout << "  avg: " << avg_time << "ms, " << "max: " << max_time << "ms, " << "min: " << min_time << "ms\n";
			total_time = 0;
			max_time = -1;
			min_time = 1000;
		}
	}

	return 0;
}



int oepc_main(RecognitionStu *shm)
{

	bool if_show_image = false;
	bool if_save_video = false;
	std::string thread_name_1 = "output_1";
	std::string thread_name_2 = "output_2";
	cv::VideoCapture capture_1;
	cv::VideoCapture capture_2;

	net.use_int8_inference = 1;  //set the int8/float32 switch before loading
	net.load_param("./model/oepc.param");
	net.load_model("./model/oepc.bin");

	//sem_init(&sem_reco[0],ftok(".", RECO1_SEM_ID));
	//sem_init(&sem_reco[1],ftok(".", RECO2_SEM_ID));
	pthread_mutex_init(&image_cond[0].mutex, NULL);
	pthread_cond_init(&image_cond[0].cond, NULL);
	pthread_mutex_init(&image_cond[1].mutex, NULL);
	pthread_cond_init(&image_cond[1].cond, NULL);

	in_people[0] = shm[0].in_total;
	in_people[1] = shm[1].in_total;
	out_people[0] = shm[0].out_total;
	out_people[1] = shm[1].out_total;

	std::thread *thread_1 = new std::thread(get_thread, 0, &shm[0], thread_name_1);
	std::thread *thread_2 = new std::thread(get_thread, 1, &shm[1], thread_name_2);

	std::thread *thread_3 = new std::thread(run_thread, 0, &shm[0], if_save_video, if_show_image, thread_name_1);
	std::thread *thread_4 = new std::thread(run_thread, 1, &shm[1], if_save_video, if_show_image, thread_name_2);
	//std::thread *thread_1 = new std::thread(run_thread, 0, thread_name_1, capture_1, if_save_video, if_show_image);
	//std::thread *thread_2 = new std::thread(run_thread, 1, thread_name_2, capture_2, if_save_video, if_show_image);

	thread_1->join();
	thread_2->join();
	thread_3->join();
	thread_4->join();

	delete thread_1;
	delete thread_2;
	delete thread_3;
	delete thread_4;

	pthread_mutex_destroy(&image_cond[0].mutex);
	pthread_cond_destroy(&image_cond[0].cond);
	pthread_mutex_destroy(&image_cond[1].mutex);
	pthread_cond_destroy(&image_cond[1].cond);
	return 0;
}












